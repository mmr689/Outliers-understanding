{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno vamos a entender cómo emplear el algoritmo de Isolatio Forest (IF) ofrecido por [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).\n",
    "\n",
    "A continuación vemos el ejemplo más básico de la propia wiki de Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "X = [[-1.1], [0.3], [0.5], [100]]\n",
    "clf = IsolationForest(random_state=0).fit(X)\n",
    "clf.predict([[0.1], [0], [90]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo las acciones son:\n",
    "1. Crear una lista de valores con los que vamos a entrenar nuestro modelo, siendo 100 un valor anómalo.\n",
    "2. Entrenar el modelo IF estableciendo una semilla para poder replicarlo en el futuro.\n",
    "3. Evaluar diferentes valores. Donde por la coherencia de los valores de entrenamiento, 90 será un valor anómalo (definido cómo -1).\n",
    "\n",
    "Los parámetros de trabajo de `sklearn.ensemble.IsolationForest()` son:\n",
    "\n",
    "- `n_estimators`: `int`, por defecto `100`. Este define cuantos estimadores (árboles) vamos a emplear para generar el modelo. Debemos ir con cuidado en encontrar el valor idóneo pues si nos excedemos podremos tener problemas de sobreajuste, además de una mayor cantidad de cómputo de entrenamiento. Un método habitual para definir este valor es aplicando validación cruzada.\n",
    "\n",
    "- `max_samples`: `auto`, `int`, `float`, por defecto `auto`. Este sirve para definir cuantas muestras vamos a emplear para entrenar el modelo. Es decir, si tenemos `1000` muestras podemos definir este valor a `100` y para entrenar cada árbol se seleccionarán 100 datos de manera aleatoria.\n",
    "    - Si `max_samples='auto'` el valor se define según `min(256, samples)`. Es decir, si las muestras son mayor o igual a 256 valores, se emplean 256 valores para entrenar. En caso de tener un tamaño de muestras inferior a 256, se emplearía el total de estas.\n",
    "    - Si `max_samples= \"int\"`, es decir definiendo un valor entero, este valor será el tamaño de entrenamiento. En caso de ser un valor superior al tamaño de las muestras, se emplearían todas.\n",
    "    - Si `max_samples = \"float\"`, es decir definiendo un valor flotante, estamos definiendo el porcentaje de muestras respecto al total que queremos emplear para entrenar. Siendo este valor un flotante entre 0 y 1.\n",
    "- `contamination`: `auto`, `float`, por defecto `auto`. Este parámetro permite definir la cantidad de *outliers* que se deben encontrar en los datos de estudio.\n",
    "    - Si `contamination = 'float'`, el valor trabaja en un rango `(0, 0.5]` (mayor a 0 y menor o igual a 0.5) y definirá que porcentaje de valores esperamos que sea outlier.\n",
    "    - Si `contamination = 'auto'`, el modelo se auto-ajustará en función de los outliers que el considere que hay.\n",
    "- `max_features`: `int`, `float`, por defecto `1.0`. Permite definir cuantas características vamos a emplear para cada árbol. En otras palabras, si suponemos que trabajamos con una tabla de cuatro características (columnas). Podemos definir este valor de tal manera que nunca se empleen la 4 opciones y así poder entender posibles relaciones independientes. Por lo tanto, en una serie temporal unidimensional este valor es 1.\n",
    "    - Si `max_features = 'int'`, este valor define cuantas características se van a emplear.\n",
    "    - Si `max_features = 'float'`, es valor define que porcentaje de características se van a emplear.\n",
    "- `bootstrap`: `bool`, por defecto `False`. Este parámetro se emplea para definir si queremos emplear o no el \"muestreo por remplazo\". Es decir, si definimos este a `False` le diremos que NO queremos y por lo tanto para entrenar cada árbol emplearemos TODOS los datos. De lo contrario, si este parámetro está a `True` solo empleariamos una porción de los datos añadiendo una variable aleatoria, pues cada árbol tendría su propio subconjunto de datos de entrenamiento. Esta cantidad de muestras vendría definido por el parámetro `max_samples`.\n",
    "- `n_jobs`: `int`, por defecto `None`. Este parámetro define cuantos procesadores se van a emplear. Es decir, permite paralelizar y entrenar varios árboles a la vez. Este valor estará limitado al número de procesadores de los que dispongamos. Si `n_jobs = none` equivale a `1`, si `n_jobs = -1` equivale a emplear TODOS los procesador disponibles.\n",
    "- `random_state`: `int`, por defecto `None`. Si le damos un valor entero, estamos definiendo la semilla de reproducibilidad. Es decir, podremos reproducir en un futuro todos aquellas combinaciones aleatorias que se generan.\n",
    "- `verbose`: `int`, por defecto `0`. Sirve para definir si queremos imprimir o no información del progreso de entrenamiento. No lo definen pero entiendo que serán valores entre `0 y 2`, donde `0` implica NADA de información (esto es lo único que dicen), `1` será información mínima y `2` (o quizás más) más información.\n",
    "- `warm_stat`: `bool`, por defecto `False`. Este se emplea para definir si entrenamos desde cero o si partimos de un estado anterior. Este es útil cuando quieres ampliar el modelo con nuevos datos de entrenamiento o también si tu conjunto de datos es muy grande y quieres hacer una carga progresiva y no saturar la memoria."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
